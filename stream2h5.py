
################################################################### SYNOPSIS
#
# convert a CrystFEL .stream file to a HDF5 .h5 file
#
################################################################### AUTHOR
#
# Alexander.Gorel@mpimf-heidelberg.mpg.de
#
################################################################### VERSION
#
# version 20.07.2016
#
################################################################### USAGE
#
# ./stream2h5 -i input.stream -o output.h5
#
################################################################### IMPORTS

import h5py #-> hdf5 file IO
import numpy #-> numerics
import re #-> regular expression
import sys #-> argv
import os #-> file checks
import getopt #-> command line parameters

################################################################### INPUT PARAMETER PROCESSING

#--------------------------------------------------- USAGE
def usage():
	print(str(sys.argv[0])+" -i <input.stream>")
	print("processes CrystFEL <input.stream> file into <input.stream.h5> file.")
	print("-h --help")
	print("-i --input")

try:
	(opts, args) = getopt.getopt(sys.argv[1:], "hi:", ["help","input="])
except getopt.GetoptError:
	usage()
	sys.exit(1)

#--------------------------------------------------- NO OPTIONS -> NOTHING TO DO
if opts.__len__()==0:
	usage()
	sys.exit()

#################################################### PROCESS DATA
inputfile=""
outputfile=""

#--------------------------------------------------- PROCESS ARGS
for (opt, arg) in opts:
#--------------------------------------------------- PRINT USAGE
	if opt in ("-h","--help"):
		usage()
		sys.exit()
#--------------------------------------------------- ASSIGN INPUT FILE
	elif opt in ("-i", "--input"):
		inputfile = arg
		if not(os.path.isfile(inputfile) and inputfile.split(".")[-1] == "stream"):
			print("error: inputfile is not a .stream file.")
			sys.exit(1)
#--------------------------------------------------- SOMETHING WENT REALLY WRONG
	else:
		print("error: unexpected option.")
		sys.exit(1)

#--------------------------------------------------- ASSIGN OUTPUT FILE

outputfile=inputfile+".h5"
if os.path.isfile(outputfile):
	print("error: outputfile "+outputfile+" already exists.")
	sys.exit(1)



################################################################### CLASSIFICATION LOGIC

string2signal_DICT={"META":{"CrystFEL stream":"crystfel_stream_format", "Generated by":"crystfel_version", "indexamajig":"crystfel_command", "----- Begin geometry file -----":"STATE_TRANSITION"},"GEOMETRY":{"adu_per_eV":"adu_per_ev", "clen":"clen", "coffset":"coffset", "photon_energy":"photon_energy", "data":"data", "max_adu":"max_adu", "/min_fs":"min_fs", "/min_ss":"min_ss", "/max_fs":"max_fs", "/max_ss":"max_ss", "/badrow_direction":"badrow_direction", "/res":"res", "/fs":"fs", "/ss":"ss", "/corner_x":"corner_x", "/corner_y":"corner_y", "/no_index":"no_index", "----- Begin chunk -----":"STATE_TRANSITION"},"CHUNK":{"Image filename:":"image_filename", "Event:":"event", "Image serial number":"image_serialnumber", "indexed_by":"indexed_by", "photon_energy_eV":"photon_energy_ev", "beam_divergence":"beam_divergence", "beam_bandwidth":"beam_bandwidth", "average_camera_length":"average_camera_length", "num_peaks":"num_peaks", "num_saturated_peaks":"num_saturated_peaks", "Peaks from peak search":"STATE_TRANSITION"},"PEAK":{"none":"STATE_TRANSITION"},"PEAKREC":{"End of peak list":"STATE_TRANSITION"},"START":{"----- Begin chunk -----":"STATE_TRANSITION1", "--- Begin crystal":"STATE_TRANSITION2"},"CRYSTAL":{"Cell parameters":"cell_parameters", "astar":"astar", "bstar":"bstar", "cstar":"cstar", "lattice_type":"lattice_type", "centering":"centering", "unique_axis":"unique_axis", "profile_radius":"profile_radius", "predict_refine/det_shift":"predict_refine/det_shift", "predict_refine/R":"predict_refine/R", "diffraction_resolution_limit":"diffraction_resolution_limit", "num_reflections":"num_reflections", "num_saturated_reflections":"num_saturated_reflections", "num_implausible_reflections":"num_implausible_reflections", "Reflections measured after indexing":"STATE_TRANSITION"},"REFLECTION":{"none":"STATE_TRANSITION"},"REFLECTIONREC":{"End of reflections":"STATE_TRANSITION"}}


#----------------------------------------------------------------------------------------- classify the input line as signal for state machine
def string2signal(**kwargs):
	result="none"
#----------------------------------------------- deal with comments
	if ";" in kwargs['string_']:
		(LHS,RHS)=kwargs['string_'].split(";",1)
	else:
		LHS=kwargs['string_']
#----------------------------------------------- interpret the uncommented part of the line
	for key in string2signal_DICT[kwargs['state_']]:
		if key in LHS:
			result = string2signal_DICT[kwargs['state_']][key]
	return result


################################################################### STATE MACHINE LOGIC

string_PARSER={("META","STATE_TRANSITION"):("GEOMETRY","none"),("GEOMETRY","STATE_TRANSITION"):("CHUNK","none"),("CHUNK","STATE_TRANSITION"):("PEAK","none"),("PEAK","none"):("PEAKREC","none"),("PEAKREC","STATE_TRANSITION"):("START","none"),("START","STATE_TRANSITION1"):("CHUNK","none"),("START","STATE_TRANSITION2"):("CRYSTAL","none"),("CRYSTAL","STATE_TRANSITION"):("REFLECTION","none"),("REFLECTION","none"):("REFLECTIONREC","none"),("REFLECTIONREC","STATE_TRANSITION"):("START","none"),("META","crystfel_stream_format"):("META","save_line"),("META","crystfel_version"):("META","save_line"),("META","crystfel_command"):("META","save_line"),("GEOMETRY","adu_per_ev"):("GEOMETRY","save_float"),("GEOMETRY","clen"):("GEOMETRY","save_string"),("GEOMETRY","coffset"):("GEOMETRY","save_float"),("GEOMETRY","photon_energy"):("GEOMETRY","save_string"),("GEOMETRY","data"):("GEOMETRY","save_string"),("GEOMETRY","max_adu"):("GEOMETRY","save_integer"),("GEOMETRY","min_fs"):("GEOMETRY","save_float"),("GEOMETRY","min_ss"):("GEOMETRY","save_float"),("GEOMETRY","max_fs"):("GEOMETRY","save_float"),("GEOMETRY","max_ss"):("GEOMETRY","save_float"),("GEOMETRY","badrow_direction"):("GEOMETRY","save_string"),("GEOMETRY","res"):("GEOMETRY","save_float"),("GEOMETRY","fs"):("GEOMETRY","save_tuple"),("GEOMETRY","ss"):("GEOMETRY","save_tuple"),("GEOMETRY","corner_x"):("GEOMETRY","save_float"),("GEOMETRY","corner_y"):("GEOMETRY","save_float"),("GEOMETRY","no_index"):("GEOMETRY","save_string"),("CHUNK","image_filename"):("CHUNK","save_string"),("CHUNK","image_serialnumber"):("CHUNK","save_integer"),("CHUNK","indexed_by"):("CHUNK","save_string"),("CHUNK","photon_energy_ev"):("CHUNK","save_float"),("CHUNK","beam_divergence"):("CHUNK","save_string"),("CHUNK","beam_bandwidth"):("CHUNK","save_string"),("CHUNK","data"):("CHUNK","save_string"),("CHUNK","detector_encoder"):("CHUNK","save_float"),("CHUNK","photon_energy_ev"):("CHUNK","save_float"),("CHUNK","average_camera_length"):("CHUNK","save_float"),("CHUNK","num_peaks"):("CHUNK","save_integer"),("CHUNK","num_saturated_peaks"):("CHUNK","save_integer"),("CHUNK","event"):("CHUNK","save_string"),("CRYSTAL","cell_parameters"):("CRYSTAL","save_line"),("CRYSTAL","astar"):("CRYSTAL","save_tuple3"),("CRYSTAL","bstar"):("CRYSTAL","save_tuple3"),("CRYSTAL","cstar"):("CRYSTAL","save_tuple3"),("CRYSTAL","lattice_type"):("CRYSTAL","save_string"),("CRYSTAL","centering"):("CRYSTAL","save_string"),("CRYSTAL","unique_axis"):("CRYSTAL","save_string"),("CRYSTAL","profile_radius"):("CRYSTAL","save_string"),("CRYSTAL","diffraction_resolution_limit"):("CRYSTAL","save_string"),("CRYSTAL","num_reflections"):("CRYSTAL","save_integer"),("CRYSTAL","num_saturated_reflections"):("CRYSTAL","save_integer"),("CRYSTAL","num_implausible_reflections"):("CRYSTAL","save_integer")}


def safe_transit(**kwargs):
	result=(kwargs["state_"],"none")
	if (kwargs["state_"],kwargs["input_"]) in kwargs["parser_"]:
		result=kwargs["parser_"][(kwargs["state_"],kwargs["input_"])]
	return result


############################################################ HELPER FUNCTIONS
#------------------------------------------------------------------ split line into argument name and argument value
def string2LHSRHS(**kwargs):
	if ":" in  kwargs["string_"] or "=" in kwargs["string_"]:
		(LHS,RHS)= re.split(":|=",kwargs["string_"],1)
	else:
		(LHS,RHS)=(kwargs["string_"],"")
	return (LHS.strip(),RHS.strip())

#------------------------------------------------------------------ convert argument name to parameter name
def string2parametername(**kwargs):
	return kwargs["string_"].lower().replace(" ","_")

################################################################### STATE MACHINE ACTIONS

def none(**kwargs):
	#print "NONE"
	return True

#------------------------------------------------------------------ save a complete line to h5
def save_line(**kwargs):
	datapath_ = kwargs["h5_group_"]+"/"+kwargs["h5_dataset_"]
	datatype = h5py.special_dtype(vlen=str)
	if not(datapath_ in kwargs["h5_FD_"]):
		kwargs["h5_FD_"][kwargs["h5_group_"]].create_dataset(kwargs["h5_dataset_"],(kwargs["h5_dataset_maxindex_"],),dtype=datatype)
	kwargs["h5_FD_"][datapath_][kwargs["h5_dataset_index_"]]=kwargs["datastring_"]
	return True

#------------------------------------------------------------------ save string parameter to h5
def save_string(**kwargs):
	datapath_ = kwargs["h5_group_"]+"/"+kwargs["h5_dataset_"]
	datatype = h5py.special_dtype(vlen=str)
	if not(datapath_ in kwargs["h5_FD_"]):
		kwargs["h5_FD_"][kwargs["h5_group_"]].create_dataset(kwargs["h5_dataset_"],(kwargs["h5_dataset_maxindex_"],),dtype=datatype)
	kwargs["h5_FD_"][datapath_][kwargs["h5_dataset_index_"]]=kwargs["datastring_"]
	return True
#------------------------------------------------------------------ save integer parameter to h5
def save_integer(**kwargs):
	datapath_ = kwargs["h5_group_"]+"/"+kwargs["h5_dataset_"]
	if not(datapath_ in kwargs["h5_FD_"]):
		kwargs["h5_FD_"][kwargs["h5_group_"]].create_dataset(kwargs["h5_dataset_"],(kwargs["h5_dataset_maxindex_"],),dtype=numpy.int32)
	res=[int(re.sub('[^0-9+-]','',kwargs["datastring_"]))]
	kwargs["h5_FD_"][datapath_][kwargs["h5_dataset_index_"]]=res
	return True
#----------------------------------------------------------------- save float parameter to h5
def save_float(**kwargs):
	datapath_ = kwargs["h5_group_"]+"/"+kwargs["h5_dataset_"]
	if not(datapath_ in kwargs["h5_FD_"]):
		kwargs["h5_FD_"][kwargs["h5_group_"]].create_dataset(kwargs["h5_dataset_"],(kwargs["h5_dataset_maxindex_"],),dtype=numpy.float64)
	res=[float(re.sub('[^0-9+-.]','',kwargs["datastring_"]))]
	kwargs["h5_FD_"][datapath_][kwargs["h5_dataset_index_"]]=res
	return True
#------------------------------------------------------------------ save float tuple parameter to h5
def save_tuple(**kwargs):
	datapath_ = kwargs["h5_group_"]+"/"+kwargs["h5_dataset_"]
	if not(datapath_ in kwargs["h5_FD_"]):
		kwargs["h5_FD_"][kwargs["h5_group_"]].create_dataset(kwargs["h5_dataset_"],(kwargs["h5_dataset_maxindex_"],2,),dtype=numpy.float64)
	#RHS=kwargs["datastring_"].replace("x","y").replace("y","")
	RHS=re.sub('[^0-9+-.]',' ',kwargs["datastring_"])
	RHS=RHS.strip()
	#print RHS
	(x,y)=RHS.split()[:2]
	res=[float(x.strip()),float(y.strip())]
	kwargs["h5_FD_"][datapath_][kwargs["h5_dataset_index_"]]=res
	return True

#------------------------------------------------------------------ save float tuple parameter to h5
def save_tuple3(**kwargs):
	datapath_ = kwargs["h5_group_"]+"/"+kwargs["h5_dataset_"]
	if not(datapath_ in kwargs["h5_FD_"]):
		kwargs["h5_FD_"][kwargs["h5_group_"]].create_dataset(kwargs["h5_dataset_"],(kwargs["h5_dataset_maxindex_"],3,),dtype=numpy.float64)
	RHS=re.sub('[^0-9+-.]',' ',kwargs["datastring_"])
	RHS=RHS.strip()
	(x,y,z)=RHS.split()[:3]
	res=[float(x.strip()),float(y.strip()),float(z.strip())]
	kwargs["h5_FD_"][datapath_][kwargs["h5_dataset_index_"]]=res
	return True
#------------------------------------------------------------------ create dataset
def check_create_datapath(**kwargs):
	datapath_ = kwargs["h5_group_"]+"/"+kwargs["h5_dataset_"]
	if not(datapath_ in kwargs["h5_FD_"]):
		kwargs["h5_FD_"][kwargs["h5_group_"]].create_dataset(kwargs["h5_dataset_"],kwargs["h5_dataset_shape_"],dtype=kwargs["h5_dataset_datatype_"],maxshape=kwargs["h5_dataset_maxshape_"])
	return True

################################################### STATE MACHINE BEHAVIOUR
action_DICT={"none":none,"save_string":save_string,"save_line":save_line,"save_integer":save_integer,"save_float":save_float,"save_tuple":save_tuple,"save_tuple3":save_tuple3}

def perform(**kwargs):
	result = False
	if kwargs["action_"] in kwargs["behave_"]:
		result = kwargs["behave_"][kwargs["action_"]](**kwargs["args_"])
	return result

################################################################### MAIN
#-------------------------------------------------------------- state machine memory
state="META"
newstate="META"
action="none"

line_num=1

#--------------------------------------------------------------

table_body_string=""
table_lines_list=list()
#-------------------------------------------------------------- open working files

fileFD=open(inputfile,"r")
h5fileFD=h5py.File(outputfile, 'w')

############################################################### process the stream file into h5
#-------------------------------------------------------------- initial setup
h5fileFD.create_group("META")

h5_group="/META"
h5_dataset=""
h5_dataset_index=0

############################################################### prescan
#-------------------------------------------------------------- count the number of chunks
chunk_num=0
line=fileFD.readline()
while line:
	if "----- Begin chunk -----" in line:
		chunk_num=chunk_num+1
	line=fileFD.readline()
#print "chunk_num:"+ str(chunk_num)

#-------------------------------------------------------------- go back to the beginning of file
fileFD.seek(0)

############################################################### import lines into h5
line = fileFD.readline()
while line:
	signal = string2signal(state_=state,string_=line)
	
#-------------------------------------------------------------- state transition logic
	(newstate,action)=safe_transit(parser_=string_PARSER,state_=state,input_=signal)
	#print state + " " + signal + " " +newstate + " " + action 
#-------------------------------------------------------------- context change logic
	if state != newstate:
		if newstate == "GEOMETRY":
			h5_group = "/GEOMETRY"
		elif newstate == "CHUNK":
			h5_group = "/CHUNK"
			if state != "GEOMETRY":
				h5_dataset_index = h5_dataset_index + 1
			else:
				h5_dataset_index = 0
		elif newstate == "PEAK":
			h5_group = "/PEAK"
#---------------------------------------------------------------- get table header
		elif newstate in {"PEAKREC","REFLECTIONREC"}:
			table_header_list =line.strip().replace("/px","").replace("/nm^-1","").replace("/","_").replace("(","").replace(")","").lower().split()
			#print table_header_list
#---------------------------------------------------------------- dump table
		elif newstate =="START":
			table_lines_list=table_body_string.strip().split("\n")
			table=numpy.array(map(lambda x: x.split(),table_lines_list))
	
			for (rownum,rowname) in enumerate(table_header_list):
				if rowname in {"h","k","l"}: 
					check_create_datapath(h5_group_=h5_group,h5_dataset_=rowname,h5_FD_=h5fileFD,h5_dataset_shape_=(chunk_num,),h5_dataset_maxshape_=(chunk_num,),h5_dataset_datatype_=h5py.special_dtype(vlen=numpy.dtype('i')))
					h5fileFD[h5_group+"/"+rowname][h5_dataset_index] = map(lambda x:int(x),table[1:,rownum])
				elif rowname == "panel":
					check_create_datapath(h5_group_=h5_group,h5_dataset_=rowname,h5_FD_=h5fileFD,h5_dataset_shape_=(chunk_num,),h5_dataset_maxshape_=(chunk_num,),h5_dataset_datatype_=h5py.special_dtype(vlen=str))
					h5fileFD[h5_group+"/"+rowname][h5_dataset_index] = "\n".join(table[1:,rownum])
				else:
					check_create_datapath(h5_group_=h5_group,h5_dataset_=rowname,h5_FD_=h5fileFD,h5_dataset_shape_=(chunk_num,),h5_dataset_maxshape_=(chunk_num,),h5_dataset_datatype_=h5py.special_dtype(vlen=numpy.dtype('f')))
					h5fileFD[h5_group+"/"+rowname][h5_dataset_index] = map(lambda x:float(x),table[1:,rownum])

			table_body_string=""
		elif newstate == "CRYSTAL":
			h5_group = "/CRYSTAL"
		elif newstate == "REFLECTION":
			h5_group = "/REFLECTION"
#-------------------------------------------------------------- create h5 group if needed
		if not (h5_group in h5fileFD):
			h5fileFD.create_group(h5_group)
	state=newstate
	
#-------------------------------------------------------------- perform action
	if state in {"META","GEOMETRY"}:
		if action in {"save_string","save_integer","save_float","save_tuple","save_tuple3"}:
			(LHS,RHS)=string2LHSRHS(string_=line)
			h5_dataset=string2parametername(string_=LHS)
			h5_datapath=h5_group+"/"+h5_dataset
			args={"h5_FD_":h5fileFD,"h5_group_":h5_group,"h5_dataset_":h5_dataset,"h5_dataset_index_":h5_dataset_index,"h5_dataset_maxindex_":1,"datastring_":RHS}
			perform(behave_=action_DICT,action_=action,args_=args)	
		elif action in {"save_line"}:
			h5_dataset=signal
			h5_datapath=h5_group+"/"+h5_dataset
			args={"h5_FD_":h5fileFD,"h5_group_":h5_group,"h5_dataset_":h5_dataset,"h5_dataset_index_":h5_dataset_index,"h5_dataset_maxindex_":1,"datastring_":line}
			perform(behave_=action_DICT,action_=action,args_=args)	
#-------------------------------------------------------------- CHUNK LOGIC
	elif state in {"CHUNK","CRYSTAL"}:
		if action in {"save_string","save_integer","save_float","save_tuple","save_tuple3"}:
			(LHS,RHS)=string2LHSRHS(string_=line)
			h5_dataset=string2parametername(string_=LHS)
			h5_datapath=h5_group+"/"+h5_dataset
			args={"h5_FD_":h5fileFD,"h5_group_":h5_group,"h5_dataset_":h5_dataset,"h5_dataset_index_":h5_dataset_index,"h5_dataset_maxindex_":chunk_num,"datastring_":RHS}
			perform(behave_=action_DICT,action_=action,args_=args)	
		elif action in {"save_line"}:
			h5_dataset=signal
			h5_datapath=h5_group+"/"+h5_dataset
			args={"h5_FD_":h5fileFD,"h5_group_":h5_group,"h5_dataset_":h5_dataset,"h5_dataset_index_":h5_dataset_index,"h5_dataset_maxindex_":chunk_num,"datastring_":line}
			perform(behave_=action_DICT,action_=action,args_=args)	
#--------------------------------------------------------------- PEAKREC LOGIC
	elif state in {"PEAKREC","REFLECTIONREC"}:
		if action == "none":
			table_body_string = table_body_string + line.strip() +"\n";
#-------------------------------------------------------------- read next line
	if (line_num % 1000000) ==0:
			print("processed "+str(line_num) +" lines.")
	line= fileFD.readline()
	line_num=line_num+1

#################################################################	
#--------------------------------------------------------------- finished reading file
h5fileFD.close()
fileFD.close()










